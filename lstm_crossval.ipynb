{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_crossval.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/meghamattikalli/lstm/blob/master/lstm_crossval.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "d7SJ8I7rAMz1",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "e3013ff0-e277-4572-dc78-df70bf1dc157"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4551b6fe-9eb4-4ace-b475-03edc1703f39\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4551b6fe-9eb4-4ace-b475-03edc1703f39\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving five_thousand.csv to five_thousand (1).csv\n",
            "Saving Indian-Female-Names1.csv to Indian-Female-Names1 (1).csv\n",
            "Saving Indian-Male-Names1.csv to Indian-Male-Names1 (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OLqI6tHwAWVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c9892672-a089-4a5d-e9f1-53f6606df08c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import io\n",
        "\n",
        "female = pd.read_csv(io.StringIO(uploaded['Indian-Female-Names1.csv'].decode('utf-8')))\n",
        "\n",
        "male = pd.read_csv(io.StringIO(uploaded['Indian-Male-Names1.csv'].decode('utf-8')))\n",
        "\n",
        "eng_word = pd.read_csv(io.StringIO(uploaded['five_thousand.csv'].decode('utf-8')))\n",
        "\n",
        "\n",
        "#parameters\n",
        "maxlen = 10\n",
        "labels = 2\n",
        "\n",
        "# Importing the dataset\n",
        "#female= pd.read_csv('Indian-Female-Names1.csv')\n",
        "#male= pd.read_csv('Indian-Male-Names1.csv')\n",
        "names=pd.concat([female,male], axis=0)\n",
        "names= names.apply(lambda x: x.astype(str).str.lower())\n",
        "names=names.iloc[:,0:1]\n",
        "names[\"type\"]=1\n",
        "names=names[names['word'].map(len) > 2]\n",
        "\n",
        "unwanted=['mr','.','moh.','@','miss','&','mrs','/','ku.','km',',','km0','-','(',')','smt','smt.','`','[','ms','1','2','3','4','5','6','7','8','9','0']\n",
        "for i in unwanted:\n",
        "    names['word'] = names.word.str.replace(i, '')\n",
        "names['word'] = names.word.str.strip()\n",
        "names=names.drop_duplicates(subset=['word'], keep='first')\n",
        "names['word'] = names.word.str.partition(\" \")\n",
        "\n",
        "\n",
        "#english words\n",
        "#eng_word = pd.read_csv('five_thousand.csv')\n",
        "eng_word = eng_word.apply(lambda x: x.astype(str).str.lower())\n",
        "eng_word['word'] = eng_word.word.str.replace('-', '')\n",
        "eng_word['word'] = eng_word.word.str.replace(\"'\", '')\n",
        "eng_word['word'] = eng_word.word.str.replace(\"/\", ' ')\n",
        "eng_word['word'] = eng_word.word.str.partition(\" \")\n",
        "\n",
        "\n",
        "#eng_pre = pd.read_csv('prepositions.csv')\n",
        "eng_word['type'] = 0\n",
        "#eng_pre['type'] = 0\n",
        "\n",
        "#concatenate names and english words\n",
        "dataset=pd.concat([names,eng_word], axis=0)\n",
        "dataset=dataset.dropna()\n",
        "\n",
        "dataset.index=[i for i in range(0,len(dataset.index))] #renaming the indices\n",
        "features = dataset['word']\n",
        "label = dataset['type']\n",
        "\n",
        "vocab = set(' '.join([str(i) for i in features]))\n",
        "\n",
        "vocab.add('END')\n",
        "len_vocab = len(vocab)\n",
        "\n",
        "print(vocab)\n",
        "print(\"vocab length is \",len_vocab)\n",
        "print (\"length of input is \",len(dataset))\n",
        "\n",
        "char_index = dict((c, i) for i, c in enumerate(vocab))\n",
        "\n",
        "print(char_index)\n",
        "\n",
        "\n",
        "#train test split\n",
        "msk = np.random.rand(len(dataset)) < 0.8\n",
        "train = dataset[msk]\n",
        "test = dataset[~msk]\n",
        "\n",
        "\n",
        "def set_flag(i):\n",
        "    tmp = np.zeros(28);\n",
        "    tmp[i] = 1\n",
        "    return(tmp)\n",
        "#take input upto max and truncate rest\n",
        "#encode to vector space(one hot encoding)\n",
        "#padd 'END' to shorter sequences\n",
        "#also convert each index to one-hot encoding\n",
        "train_X = []\n",
        "train_Y = []\n",
        "trunc_train_name = [str(i)[0:maxlen] for i in train.word]\n",
        "for i in trunc_train_name:\n",
        "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
        "    for k in range(0,maxlen - len(str(i))):\n",
        "        tmp.append(set_flag(char_index[\"END\"]))\n",
        "    train_X.append(tmp)\n",
        "for i in train.type:\n",
        "    if i == 0:\n",
        "        train_Y.append([1,0])\n",
        "    else:\n",
        "        train_Y.append([0,1])\n",
        "\n",
        "np.asarray(train_X).shape\n",
        "\n",
        "np.asarray(train_Y).shape\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'p', 's', 'o', 'i', 'n', 'j', 'h', 'x', 'z', ' ', 'f', 'd', 'k', 'l', 'e', 't', 'u', 'a', 'r', 'c', 'y', 'g', 'v', 'q', 'm', 'END', 'b', 'w'}\n",
            "vocab length is  28\n",
            "length of input is  18716\n",
            "{'p': 0, 's': 1, 'o': 2, 'i': 3, 'n': 4, 'j': 5, 'h': 6, 'x': 7, 'z': 8, ' ': 9, 'f': 10, 'd': 11, 'k': 12, 'l': 13, 'e': 14, 't': 15, 'u': 16, 'a': 17, 'r': 18, 'c': 19, 'y': 20, 'g': 21, 'v': 22, 'q': 23, 'm': 24, 'END': 25, 'b': 26, 'w': 27}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14863, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "VbolUBKl26BK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "37hjy9FyD5RZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def build_classifier():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(512, return_sequences=False))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(2))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2wCbwV04AXGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36899
        },
        "outputId": "17eb7a85-7d2e-4628-a821-ef9dc8c83875"
      },
      "cell_type": "code",
      "source": [
        "train_X=np.array(train_X)\n",
        "train_Y=np.array(train_Y)\n",
        "#test_Y=np.array(test_Y)\n",
        "#test_X=np.array(test_X)\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 20)\n",
        "accuracies = cross_val_score(estimator = classifier, X = train_X, y = train_Y, cv = 2, n_jobs = -1)\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "JoblibInternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\n    return fn(*args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\n    options, feed_dict, fetch_list, target_list, run_metadata)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\n    run_metadata)\ntensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(10, 512), b.shape=(512, 512), m=10, n=512, k=512\n\t [[Node: lstm_1/while/MatMul_7 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/AddN_13\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/while/Switch_2:1, lstm_1/while/MatMul_7/Enter)]]\n\t [[Node: metrics/acc/Mean/_107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3328_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 209, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 151, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 1002, in fit\n    validation_steps=validation_steps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1705, in fit\n    validation_steps=validation_steps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1236, in _fit_loop\n    outs = f(ins_batch)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2482, in __call__\n    **self.session_kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 877, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1100, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\n    run_metadata)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(10, 512), b.shape=(512, 512), m=10, n=512, k=512\n\t [[Node: lstm_1/while/MatMul_7 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/AddN_13\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/while/Switch_2:1, lstm_1/while/MatMul_7/Enter)]]\n\t [[Node: metrics/acc/Mean/_107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3328_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'lstm_1/while/MatMul_7', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-f7262d93c938>\", line 6, in <module>\n    accuracies = cross_val_score(estimator = classifier, X = train_X, y = train_Y, cv = 2, n_jobs = -1)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 342, in cross_val_score\n    pre_dispatch=pre_dispatch)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 206, in cross_validate\n    for train, test in cv.split(X, y, groups))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 749, in __call__\n    n_jobs = self._initialize_backend()\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 547, in _initialize_backend\n    **self._backend_args)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 317, in configure\n    self._pool = MemmapingPool(n_jobs, **backend_args)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\", line 600, in __init__\n    super(MemmapingPool, self).__init__(**poolargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\", line 420, in __init__\n    super(PicklingPool, self).__init__(**poolargs)\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n    self._repopulate_pool()\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n    w.start()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\n    self._popen = self._Popen(self)\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n    return Popen(process_obj)\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 20, in __init__\n    self._launch(process_obj)\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 74, in _launch\n    code = process_obj._bootstrap()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 209, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 140, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n  File \"<ipython-input-7-55700185ea87>\", line 4, in build_classifier\n    model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 497, in add\n    layer(x)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 500, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 2112, in call\n    initial_state=initial_state)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 609, in call\n    input_length=timesteps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2771, in rnn\n    swap_memory=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2757, in _step\n    tuple(constants))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 600, in step\n    return self.cell.call(inputs, states, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 1908, in call\n    self.recurrent_kernel_o))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 1076, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 2018, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4456, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(10, 512), b.shape=(512, 512), m=10, n=512, k=512\n\t [[Node: lstm_1/while/MatMul_7 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/AddN_13\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/while/Switch_2:1, lstm_1/while/MatMul_7/Enter)]]\n\t [[Node: metrics/acc/Mean/_107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3328_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nInternalError                                      Thu Aug 30 17:04:36 2018\nPID: 12556                                   Python 3.6.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), {'score': <function _passthrough_scorer>}, array([ 7432,  7433,  7434, ..., 14860, 14861, 14862]), array([   0,    1,    2, ..., 7429, 7430, 7431]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), {'score': <function _passthrough_scorer>}, array([ 7432,  7433,  7434, ..., 14860, 14861, 14862]), array([   0,    1,    2, ..., 7429, 7430, 7431]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), scorer={'score': <function _passthrough_scorer>}, train=array([ 7432,  7433,  7434, ..., 14860, 14861, 14862]), test=array([   0,    1,    2, ..., 7429, 7430, 7431]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])\n        y_train = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), sample_weight=None, **kwargs={})\n    204         else:\n    205             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    206         self.n_classes_ = len(self.classes_)\n    207         if sample_weight is not None:\n    208             kwargs['sample_weight'] = sample_weight\n--> 209         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])\n        y = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        kwargs = {}\n    210 \n    211     def predict(self, x, **kwargs):\n    212         \"\"\"Returns the class predictions for the given test data.\n    213 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), **kwargs={})\n    146             y = to_categorical(y)\n    147 \n    148         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    149         fit_args.update(kwargs)\n    150 \n--> 151         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Sequential.fit of <keras.models.Sequential object>>\n        x = memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])\n        y = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        fit_args = {'batch_size': 10, 'epochs': 20}\n    152 \n    153         return history\n    154 \n    155     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/models.py in fit(self=<keras.models.Sequential object>, x=memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), batch_size=10, epochs=20, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n    997                               shuffle=shuffle,\n    998                               class_weight=class_weight,\n    999                               sample_weight=sample_weight,\n   1000                               initial_epoch=initial_epoch,\n   1001                               steps_per_epoch=steps_per_epoch,\n-> 1002                               validation_steps=validation_steps)\n        validation_steps = None\n   1003 \n   1004     def evaluate(self, x=None, y=None,\n   1005                  batch_size=None,\n   1006                  verbose=1,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=[memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])], y=[array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])], batch_size=10, epochs=20, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n   1700                               verbose=verbose, callbacks=callbacks,\n   1701                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n   1702                               callback_metrics=callback_metrics,\n   1703                               initial_epoch=initial_epoch,\n   1704                               steps_per_epoch=steps_per_epoch,\n-> 1705                               validation_steps=validation_steps)\n        validation_steps = None\n   1706 \n   1707     def evaluate(self, x=None, y=None,\n   1708                  batch_size=None,\n   1709                  verbose=1,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in _fit_loop(self=<keras.engine.training.Model object>, f=<keras.backend.tensorflow_backend.Function object>, ins=[memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), array([1., 1., 1., ..., 1., 1., 1.], dtype=float32), 1.0], out_labels=['loss', 'acc'], batch_size=10, epochs=20, verbose=1, callbacks=<keras.callbacks.CallbackList object>, val_f=None, val_ins=[], shuffle=True, callback_metrics=['loss', 'acc'], initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n   1231                     batch_logs['size'] = len(batch_ids)\n   1232                     callbacks.on_batch_begin(batch_index, batch_logs)\n   1233                     for i in indices_for_conversion_to_dense:\n   1234                         ins_batch[i] = ins_batch[i].toarray()\n   1235 \n-> 1236                     outs = f(ins_batch)\n        outs = undefined\n        f = <keras.backend.tensorflow_backend.Function object>\n        ins_batch = [array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 1.0]\n   1237                     if not isinstance(outs, list):\n   1238                         outs = [outs]\n   1239                     for l, o in zip(out_labels, outs):\n   1240                         batch_logs[l] = o\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in __call__(self=<keras.backend.tensorflow_backend.Function object>, inputs=[array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 1.0])\n   2477                 value = (indices, sparse_coo.data, sparse_coo.shape)\n   2478             feed_dict[tensor] = value\n   2479         fetches = self.outputs + [self.updates_op] + self.fetches\n   2480         session = get_session()\n   2481         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n-> 2482                               **self.session_kwargs)\n        self.session_kwargs = {}\n   2483         return updated[:len(self.outputs)]\n   2484 \n   2485 \n   2486 def function(inputs, outputs, updates=None, **kwargs):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self=<tensorflow.python.client.session.Session object>, fetches=[<tf.Tensor 'loss/mul:0' shape=() dtype=float32>, <tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>, <tf.Operation 'training/group_deps' type=NoOp>], feed_dict={<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: 1.0}, options=None, run_metadata=None)\n    872         compat.as_bytes(options.SerializeToString())) if options else None\n    873     run_metadata_ptr = tf_session.TF_NewBuffer() if run_metadata else None\n    874 \n    875     try:\n    876       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 877                          run_metadata_ptr)\n        run_metadata_ptr = None\n    878       if run_metadata:\n    879         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n    880         run_metadata.ParseFromString(compat.as_bytes(proto_data))\n    881     finally:\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self=<tensorflow.python.client.session.Session object>, handle=None, fetches=[<tf.Tensor 'loss/mul:0' shape=() dtype=float32>, <tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>, <tf.Operation 'training/group_deps' type=NoOp>], feed_dict={<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: 1.0}, options=None, run_metadata=None)\n   1095     final_targets = fetch_handler.targets()\n   1096     # We only want to really perform the run if fetches or targets are provided,\n   1097     # or if the call is a partial run that specifies feeds.\n   1098     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1099       results = self._do_run(handle, final_targets, final_fetches,\n-> 1100                              feed_dict_tensor, options, run_metadata)\n        feed_dict_tensor = {<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...  [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1., 0.],\n       [0., 1.],\n       [1., 0....       [0., 1.],\n       [1., 0.]], dtype=float32), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: array(True)}\n        options = None\n        run_metadata = None\n   1101     else:\n   1102       results = []\n   1103     return fetch_handler.build_results(self, results)\n   1104 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self=<tensorflow.python.client.session.Session object>, handle=None, target_list=[<tf.Operation 'training/group_deps' type=NoOp>], fetch_list=[<tf.Tensor 'loss/mul:0' shape=() dtype=float32>, <tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>], feed_dict={<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...  [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1., 0.],\n       [0., 1.],\n       [1., 0....       [0., 1.],\n       [1., 0.]], dtype=float32), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: array(True)}, options=None, run_metadata=None)\n   1267         raise RuntimeError('partial_run() requires empty target_list.')\n   1268       return self._call_tf_sessionprun(handle, feed_dict, fetch_list)\n   1269 \n   1270     if handle is None:\n   1271       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-> 1272                            run_metadata)\n        run_metadata = None\n   1273     else:\n   1274       return self._do_call(_prun_fn, handle, feeds, fetches)\n   1275 \n   1276   def _do_call(self, fn, *args):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self=<tensorflow.python.client.session.Session object>, fn=<function BaseSession._do_run.<locals>._run_fn>, *args=({<tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28a50> >: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...  [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28ba0> >: array([[1., 0.],\n       [0., 1.],\n       [1., 0....       [0., 1.],\n       [1., 0.]], dtype=float32), <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28b10> >: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28b40> >: array(True)}, [<tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28bd0> >, <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28c00> >], [<Swig Object of type 'TF_Operation *'>], None, None))\n   1286         try:\n   1287           op = self._graph.get_operation_by_name(node_name)\n   1288           node_def = op.node_def\n   1289         except KeyError:\n   1290           pass\n-> 1291       raise type(e)(node_def, op, message)\n        e = undefined\n        node_def = name: \"lstm_1/while/MatMul_7\"\nop: \"MatMul\"\ninput... key: \"transpose_b\"\n  value {\n    b: false\n  }\n}\n\n        op = <tf.Operation 'lstm_1/while/MatMul_7' type=MatMul>\n        message = 'Blas GEMM launch failed : a.shape=(10, 512), b.s...job:localhost/replica:0/task:0/device:CPU:0\"]()]]'\n   1292 \n   1293   def _extend_graph(self):\n   1294     with self._graph._session_run_lock():  # pylint: disable=protected-access\n   1295       tf_session.ExtendSession(self._session)\n\nInternalError: Blas GEMM launch failed : a.shape=(10, 512), b.shape=(512, 512), m=10, n=512, k=512\n\t [[Node: lstm_1/while/MatMul_7 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/AddN_13\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/while/Switch_2:1, lstm_1/while/MatMul_7/Enter)]]\n\t [[Node: metrics/acc/Mean/_107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3328_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'lstm_1/while/MatMul_7', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-f7262d93c938>\", line 6, in <module>\n    accuracies = cross_val_score(estimator = classifier, X = train_X, y = train_Y, cv = 2, n_jobs = -1)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 342, in cross_val_score\n    pre_dispatch=pre_dispatch)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 206, in cross_validate\n    for train, test in cv.split(X, y, groups))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 749, in __call__\n    n_jobs = self._initialize_backend()\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 547, in _initialize_backend\n    **self._backend_args)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 317, in configure\n    self._pool = MemmapingPool(n_jobs, **backend_args)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\", line 600, in __init__\n    super(MemmapingPool, self).__init__(**poolargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\", line 420, in __init__\n    super(PicklingPool, self).__init__(**poolargs)\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n    self._repopulate_pool()\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n    w.start()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\n    self._popen = self._Popen(self)\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n    return Popen(process_obj)\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 20, in __init__\n    self._launch(process_obj)\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 74, in _launch\n    code = process_obj._bootstrap()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 209, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 140, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n  File \"<ipython-input-7-55700185ea87>\", line 4, in build_classifier\n    model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 497, in add\n    layer(x)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 500, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 2112, in call\n    initial_state=initial_state)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 609, in call\n    input_length=timesteps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2771, in rnn\n    swap_memory=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2757, in _step\n    tuple(constants))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 600, in step\n    return self.cell.call(inputs, states, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 1908, in call\n    self.recurrent_kernel_o))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 1076, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 2018, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4456, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(10, 512), b.shape=(512, 512), m=10, n=512, k=512\n\t [[Node: lstm_1/while/MatMul_7 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/AddN_13\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/while/Switch_2:1, lstm_1/while/MatMul_7/Enter)]]\n\t [[Node: metrics/acc/Mean/_107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3328_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\n___________________________________________________________________________\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nInternalError                                      Thu Aug 30 17:04:36 2018\nPID: 12556                                   Python 3.6.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), {'score': <function _passthrough_scorer>}, array([ 7432,  7433,  7434, ..., 14860, 14861, 14862]), array([   0,    1,    2, ..., 7429, 7430, 7431]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), {'score': <function _passthrough_scorer>}, array([ 7432,  7433,  7434, ..., 14860, 14861, 14862]), array([   0,    1,    2, ..., 7429, 7430, 7431]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), scorer={'score': <function _passthrough_scorer>}, train=array([ 7432,  7433,  7434, ..., 14860, 14861, 14862]), test=array([   0,    1,    2, ..., 7429, 7430, 7431]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])\n        y_train = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), sample_weight=None, **kwargs={})\n    204         else:\n    205             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    206         self.n_classes_ = len(self.classes_)\n    207         if sample_weight is not None:\n    208             kwargs['sample_weight'] = sample_weight\n--> 209         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])\n        y = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        kwargs = {}\n    210 \n    211     def predict(self, x, **kwargs):\n    212         \"\"\"Returns the class predictions for the given test data.\n    213 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), **kwargs={})\n    146             y = to_categorical(y)\n    147 \n    148         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    149         fit_args.update(kwargs)\n    150 \n--> 151         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Sequential.fit of <keras.models.Sequential object>>\n        x = memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])\n        y = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        fit_args = {'batch_size': 10, 'epochs': 20}\n    152 \n    153         return history\n    154 \n    155     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/models.py in fit(self=<keras.models.Sequential object>, x=memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), batch_size=10, epochs=20, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n    997                               shuffle=shuffle,\n    998                               class_weight=class_weight,\n    999                               sample_weight=sample_weight,\n   1000                               initial_epoch=initial_epoch,\n   1001                               steps_per_epoch=steps_per_epoch,\n-> 1002                               validation_steps=validation_steps)\n        validation_steps = None\n   1003 \n   1004     def evaluate(self, x=None, y=None,\n   1005                  batch_size=None,\n   1006                  verbose=1,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=[memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])], y=[array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])], batch_size=10, epochs=20, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n   1700                               verbose=verbose, callbacks=callbacks,\n   1701                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n   1702                               callback_metrics=callback_metrics,\n   1703                               initial_epoch=initial_epoch,\n   1704                               steps_per_epoch=steps_per_epoch,\n-> 1705                               validation_steps=validation_steps)\n        validation_steps = None\n   1706 \n   1707     def evaluate(self, x=None, y=None,\n   1708                  batch_size=None,\n   1709                  verbose=1,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in _fit_loop(self=<keras.engine.training.Model object>, f=<keras.backend.tensorflow_backend.Function object>, ins=[memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), array([1., 1., 1., ..., 1., 1., 1.], dtype=float32), 1.0], out_labels=['loss', 'acc'], batch_size=10, epochs=20, verbose=1, callbacks=<keras.callbacks.CallbackList object>, val_f=None, val_ins=[], shuffle=True, callback_metrics=['loss', 'acc'], initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n   1231                     batch_logs['size'] = len(batch_ids)\n   1232                     callbacks.on_batch_begin(batch_index, batch_logs)\n   1233                     for i in indices_for_conversion_to_dense:\n   1234                         ins_batch[i] = ins_batch[i].toarray()\n   1235 \n-> 1236                     outs = f(ins_batch)\n        outs = undefined\n        f = <keras.backend.tensorflow_backend.Function object>\n        ins_batch = [array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 1.0]\n   1237                     if not isinstance(outs, list):\n   1238                         outs = [outs]\n   1239                     for l, o in zip(out_labels, outs):\n   1240                         batch_logs[l] = o\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in __call__(self=<keras.backend.tensorflow_backend.Function object>, inputs=[array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 1.0])\n   2477                 value = (indices, sparse_coo.data, sparse_coo.shape)\n   2478             feed_dict[tensor] = value\n   2479         fetches = self.outputs + [self.updates_op] + self.fetches\n   2480         session = get_session()\n   2481         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n-> 2482                               **self.session_kwargs)\n        self.session_kwargs = {}\n   2483         return updated[:len(self.outputs)]\n   2484 \n   2485 \n   2486 def function(inputs, outputs, updates=None, **kwargs):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self=<tensorflow.python.client.session.Session object>, fetches=[<tf.Tensor 'loss/mul:0' shape=() dtype=float32>, <tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>, <tf.Operation 'training/group_deps' type=NoOp>], feed_dict={<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: 1.0}, options=None, run_metadata=None)\n    872         compat.as_bytes(options.SerializeToString())) if options else None\n    873     run_metadata_ptr = tf_session.TF_NewBuffer() if run_metadata else None\n    874 \n    875     try:\n    876       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 877                          run_metadata_ptr)\n        run_metadata_ptr = None\n    878       if run_metadata:\n    879         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n    880         run_metadata.ParseFromString(compat.as_bytes(proto_data))\n    881     finally:\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self=<tensorflow.python.client.session.Session object>, handle=None, fetches=[<tf.Tensor 'loss/mul:0' shape=() dtype=float32>, <tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>, <tf.Operation 'training/group_deps' type=NoOp>], feed_dict={<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: 1.0}, options=None, run_metadata=None)\n   1095     final_targets = fetch_handler.targets()\n   1096     # We only want to really perform the run if fetches or targets are provided,\n   1097     # or if the call is a partial run that specifies feeds.\n   1098     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1099       results = self._do_run(handle, final_targets, final_fetches,\n-> 1100                              feed_dict_tensor, options, run_metadata)\n        feed_dict_tensor = {<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...  [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1., 0.],\n       [0., 1.],\n       [1., 0....       [0., 1.],\n       [1., 0.]], dtype=float32), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: array(True)}\n        options = None\n        run_metadata = None\n   1101     else:\n   1102       results = []\n   1103     return fetch_handler.build_results(self, results)\n   1104 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self=<tensorflow.python.client.session.Session object>, handle=None, target_list=[<tf.Operation 'training/group_deps' type=NoOp>], fetch_list=[<tf.Tensor 'loss/mul:0' shape=() dtype=float32>, <tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>], feed_dict={<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...  [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1., 0.],\n       [0., 1.],\n       [1., 0....       [0., 1.],\n       [1., 0.]], dtype=float32), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: array(True)}, options=None, run_metadata=None)\n   1267         raise RuntimeError('partial_run() requires empty target_list.')\n   1268       return self._call_tf_sessionprun(handle, feed_dict, fetch_list)\n   1269 \n   1270     if handle is None:\n   1271       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-> 1272                            run_metadata)\n        run_metadata = None\n   1273     else:\n   1274       return self._do_call(_prun_fn, handle, feeds, fetches)\n   1275 \n   1276   def _do_call(self, fn, *args):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self=<tensorflow.python.client.session.Session object>, fn=<function BaseSession._do_run.<locals>._run_fn>, *args=({<tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28a50> >: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...  [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28ba0> >: array([[1., 0.],\n       [0., 1.],\n       [1., 0....       [0., 1.],\n       [1., 0.]], dtype=float32), <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28b10> >: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28b40> >: array(True)}, [<tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28bd0> >, <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28c00> >], [<Swig Object of type 'TF_Operation *'>], None, None))\n   1286         try:\n   1287           op = self._graph.get_operation_by_name(node_name)\n   1288           node_def = op.node_def\n   1289         except KeyError:\n   1290           pass\n-> 1291       raise type(e)(node_def, op, message)\n        e = undefined\n        node_def = name: \"lstm_1/while/MatMul_7\"\nop: \"MatMul\"\ninput... key: \"transpose_b\"\n  value {\n    b: false\n  }\n}\n\n        op = <tf.Operation 'lstm_1/while/MatMul_7' type=MatMul>\n        message = 'Blas GEMM launch failed : a.shape=(10, 512), b.s...job:localhost/replica:0/task:0/device:CPU:0\"]()]]'\n   1292 \n   1293   def _extend_graph(self):\n   1294     with self._graph._session_run_lock():  # pylint: disable=protected-access\n   1295       tf_session.ExtendSession(self._session)\n\nInternalError: Blas GEMM launch failed : a.shape=(10, 512), b.shape=(512, 512), m=10, n=512, k=512\n\t [[Node: lstm_1/while/MatMul_7 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/AddN_13\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/while/Switch_2:1, lstm_1/while/MatMul_7/Enter)]]\n\t [[Node: metrics/acc/Mean/_107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3328_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'lstm_1/while/MatMul_7', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-f7262d93c938>\", line 6, in <module>\n    accuracies = cross_val_score(estimator = classifier, X = train_X, y = train_Y, cv = 2, n_jobs = -1)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 342, in cross_val_score\n    pre_dispatch=pre_dispatch)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 206, in cross_validate\n    for train, test in cv.split(X, y, groups))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 749, in __call__\n    n_jobs = self._initialize_backend()\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 547, in _initialize_backend\n    **self._backend_args)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 317, in configure\n    self._pool = MemmapingPool(n_jobs, **backend_args)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\", line 600, in __init__\n    super(MemmapingPool, self).__init__(**poolargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\", line 420, in __init__\n    super(PicklingPool, self).__init__(**poolargs)\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n    self._repopulate_pool()\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n    w.start()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\n    self._popen = self._Popen(self)\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n    return Popen(process_obj)\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 20, in __init__\n    self._launch(process_obj)\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 74, in _launch\n    code = process_obj._bootstrap()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 209, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 140, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n  File \"<ipython-input-7-55700185ea87>\", line 4, in build_classifier\n    model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 497, in add\n    layer(x)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 500, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 2112, in call\n    initial_state=initial_state)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 609, in call\n    input_length=timesteps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2771, in rnn\n    swap_memory=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2757, in _step\n    tuple(constants))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 600, in step\n    return self.cell.call(inputs, states, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 1908, in call\n    self.recurrent_kernel_o))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 1076, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 2018, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4456, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(10, 512), b.shape=(512, 512), m=10, n=512, k=512\n\t [[Node: lstm_1/while/MatMul_7 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/AddN_13\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/while/Switch_2:1, lstm_1/while/MatMul_7/Enter)]]\n\t [[Node: metrics/acc/Mean/_107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3328_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\n___________________________________________________________________________",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mJoblibInternalError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f7262d93c938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#test_X=np.array(test_X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJoblibInternalError\u001b[0m: JoblibInternalError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f424453c4b0, file \"/...3.6/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f424453c4b0, file \"/...3.6/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<google.colab._kernel.Kernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()', 'silent': False, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 30, 17, 4, 23, 600983, tzinfo=tzlocal()), 'msg_id': 'b877447e970f4b70bebcbcab7019e1f6', 'msg_type': 'execute_request', 'session': '2ebb7a4094114d5198333467acff05f9', 'username': 'username', 'version': '5.0'}, 'metadata': {'colab': {'cell_id': '2wCbwV04AXGH'}}, 'msg_id': 'b877447e970f4b70bebcbcab7019e1f6', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <google.colab._kernel.Kernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2ebb7a4094114d5198333467acff05f9']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()', 'silent': False, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 30, 17, 4, 23, 600983, tzinfo=tzlocal()), 'msg_id': 'b877447e970f4b70bebcbcab7019e1f6', 'msg_type': 'execute_request', 'session': '2ebb7a4094114d5198333467acff05f9', 'username': 'username', 'version': '5.0'}, 'metadata': {'colab': {'cell_id': '2wCbwV04AXGH'}}, 'msg_id': 'b877447e970f4b70bebcbcab7019e1f6', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in execute_request(self=<google.colab._kernel.Kernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2ebb7a4094114d5198333467acff05f9'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()', 'silent': False, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 30, 17, 4, 23, 600983, tzinfo=tzlocal()), 'msg_id': 'b877447e970f4b70bebcbcab7019e1f6', 'msg_type': 'execute_request', 'session': '2ebb7a4094114d5198333467acff05f9', 'username': 'username', 'version': '5.0'}, 'metadata': {'colab': {'cell_id': '2wCbwV04AXGH'}}, 'msg_id': 'b877447e970f4b70bebcbcab7019e1f6', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py in do_execute(self=<google.colab._kernel.Kernel object>, code='train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <google.colab._shell.Shell object>>\n        code = 'train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py in run_cell(self=<google.colab._shell.Shell object>, *args=('train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <google.colab._shell.Shell object>>\n        args = ('train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<google.colab._shell.Shell object>, raw_cell='train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<google.colab._shell.Shell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-10-f7262d93c938>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f41d68b9c50, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <google.colab._shell.Shell object>>\n        code = <code object <module> at 0x7f41d7fbc270, file \"<ipython-input-10-f7262d93c938>\", line 6>\n        result = <ExecutionResult object at 7f41d68b9c50, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_code(self=<google.colab._shell.Shell object>, code_obj=<code object <module> at 0x7f41d7fbc270, file \"<ipython-input-10-f7262d93c938>\", line 6>, result=<ExecutionResult object at 7f41d68b9c50, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f41d7fbc270, file \"<ipython-input-10-f7262d93c938>\", line 6>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Embedding': <class 'keras.layers.embeddings.Embedding'>, 'In': ['', 'import os\\n\\nfrom google.colab import files\\nuploaded = files.upload()', '\\nfrom __future__ import print_function\\n\\nfrom skl...n = accuracies.mean()\\nvariance = accuracies.std()', '\\nfrom __future__ import print_function\\n\\nfrom skl...n = accuracies.mean()\\nvariance = accuracies.std()', 'import os\\n\\nfrom google.colab import files\\nuploaded = files.upload()', '\\nfrom __future__ import print_function\\n\\nfrom skl...asarray(train_X).shape\\n\\nnp.asarray(train_Y).shape', '\\nfrom __future__ import print_function\\n\\nfrom skl...asarray(train_X).shape\\n\\nnp.asarray(train_Y).shape', \"\\ndef build_classifier():\\n  model = Sequential()\\n...mizer='adam',metrics=['accuracy'])\\n  return model\", 'classifier = KerasClassifier(build_fn = build_cl...n = accuracies.mean()\\nvariance = accuracies.std()', 'train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()', 'train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()'], 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'LSTM': <class 'keras.layers.recurrent.LSTM'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {5: (15033, 2), 6: (14863, 2)}, 'Sequential': ...\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'Embedding': <class 'keras.layers.embeddings.Embedding'>, 'In': ['', 'import os\\n\\nfrom google.colab import files\\nuploaded = files.upload()', '\\nfrom __future__ import print_function\\n\\nfrom skl...n = accuracies.mean()\\nvariance = accuracies.std()', '\\nfrom __future__ import print_function\\n\\nfrom skl...n = accuracies.mean()\\nvariance = accuracies.std()', 'import os\\n\\nfrom google.colab import files\\nuploaded = files.upload()', '\\nfrom __future__ import print_function\\n\\nfrom skl...asarray(train_X).shape\\n\\nnp.asarray(train_Y).shape', '\\nfrom __future__ import print_function\\n\\nfrom skl...asarray(train_X).shape\\n\\nnp.asarray(train_Y).shape', \"\\ndef build_classifier():\\n  model = Sequential()\\n...mizer='adam',metrics=['accuracy'])\\n  return model\", 'classifier = KerasClassifier(build_fn = build_cl...n = accuracies.mean()\\nvariance = accuracies.std()', 'train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()', 'train_X=np.array(train_X)\\ntrain_Y=np.array(train...n = accuracies.mean()\\nvariance = accuracies.std()'], 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'LSTM': <class 'keras.layers.recurrent.LSTM'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {5: (15033, 2), 6: (14863, 2)}, 'Sequential': <class ...\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/content/<ipython-input-10-f7262d93c938> in <module>()\n      1 train_X=np.array(train_X)\n      2 train_Y=np.array(train_Y)\n      3 #test_Y=np.array(test_Y)\n      4 #test_X=np.array(test_X)\n      5 classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 20)\n----> 6 accuracies = cross_val_score(estimator = classifier, X = train_X, y = train_Y, cv = 2, n_jobs = -1)\n      7 mean = accuracies.mean()\n      8 variance = accuracies.std()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), groups=None, scoring=None, cv=2, n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), groups=None, scoring={'score': <function _passthrough_scorer>}, cv=KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=2, random_state=None, shuffle=False)>\n        X = array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 1., 0., 0.]]])\n        y = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nInternalError                                      Thu Aug 30 17:04:36 2018\nPID: 12556                                   Python 3.6.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), {'score': <function _passthrough_scorer>}, array([ 7432,  7433,  7434, ..., 14860, 14861, 14862]), array([   0,    1,    2, ..., 7429, 7430, 7431]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), {'score': <function _passthrough_scorer>}, array([ 7432,  7433,  7434, ..., 14860, 14861, 14862]), array([   0,    1,    2, ..., 7429, 7430, 7431]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), scorer={'score': <function _passthrough_scorer>}, train=array([ 7432,  7433,  7434, ..., 14860, 14861, 14862]), test=array([   0,    1,    2, ..., 7429, 7430, 7431]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])\n        y_train = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), sample_weight=None, **kwargs={})\n    204         else:\n    205             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    206         self.n_classes_ = len(self.classes_)\n    207         if sample_weight is not None:\n    208             kwargs['sample_weight'] = sample_weight\n--> 209         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])\n        y = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        kwargs = {}\n    210 \n    211     def predict(self, x, **kwargs):\n    212         \"\"\"Returns the class predictions for the given test data.\n    213 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), **kwargs={})\n    146             y = to_categorical(y)\n    147 \n    148         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    149         fit_args.update(kwargs)\n    150 \n--> 151         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Sequential.fit of <keras.models.Sequential object>>\n        x = memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])\n        y = array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])\n        fit_args = {'batch_size': 10, 'epochs': 20}\n    152 \n    153         return history\n    154 \n    155     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/models.py in fit(self=<keras.models.Sequential object>, x=memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), y=array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), batch_size=10, epochs=20, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n    997                               shuffle=shuffle,\n    998                               class_weight=class_weight,\n    999                               sample_weight=sample_weight,\n   1000                               initial_epoch=initial_epoch,\n   1001                               steps_per_epoch=steps_per_epoch,\n-> 1002                               validation_steps=validation_steps)\n        validation_steps = None\n   1003 \n   1004     def evaluate(self, x=None, y=None,\n   1005                  batch_size=None,\n   1006                  verbose=1,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=[memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]])], y=[array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]])], batch_size=10, epochs=20, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n   1700                               verbose=verbose, callbacks=callbacks,\n   1701                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,\n   1702                               callback_metrics=callback_metrics,\n   1703                               initial_epoch=initial_epoch,\n   1704                               steps_per_epoch=steps_per_epoch,\n-> 1705                               validation_steps=validation_steps)\n        validation_steps = None\n   1706 \n   1707     def evaluate(self, x=None, y=None,\n   1708                  batch_size=None,\n   1709                  verbose=1,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in _fit_loop(self=<keras.engine.training.Model object>, f=<keras.backend.tensorflow_backend.Function object>, ins=[memmap([[[1., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 1., 0., 0.]]]), array([[0, 1],\n       [0, 1],\n       [0, 1],\n   .....,\n       [1, 0],\n       [1, 0],\n       [1, 0]]), array([1., 1., 1., ..., 1., 1., 1.], dtype=float32), 1.0], out_labels=['loss', 'acc'], batch_size=10, epochs=20, verbose=1, callbacks=<keras.callbacks.CallbackList object>, val_f=None, val_ins=[], shuffle=True, callback_metrics=['loss', 'acc'], initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n   1231                     batch_logs['size'] = len(batch_ids)\n   1232                     callbacks.on_batch_begin(batch_index, batch_logs)\n   1233                     for i in indices_for_conversion_to_dense:\n   1234                         ins_batch[i] = ins_batch[i].toarray()\n   1235 \n-> 1236                     outs = f(ins_batch)\n        outs = undefined\n        f = <keras.backend.tensorflow_backend.Function object>\n        ins_batch = [array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 1.0]\n   1237                     if not isinstance(outs, list):\n   1238                         outs = [outs]\n   1239                     for l, o in zip(out_labels, outs):\n   1240                         batch_logs[l] = o\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in __call__(self=<keras.backend.tensorflow_backend.Function object>, inputs=[array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), 1.0])\n   2477                 value = (indices, sparse_coo.data, sparse_coo.shape)\n   2478             feed_dict[tensor] = value\n   2479         fetches = self.outputs + [self.updates_op] + self.fetches\n   2480         session = get_session()\n   2481         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n-> 2482                               **self.session_kwargs)\n        self.session_kwargs = {}\n   2483         return updated[:len(self.outputs)]\n   2484 \n   2485 \n   2486 def function(inputs, outputs, updates=None, **kwargs):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self=<tensorflow.python.client.session.Session object>, fetches=[<tf.Tensor 'loss/mul:0' shape=() dtype=float32>, <tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>, <tf.Operation 'training/group_deps' type=NoOp>], feed_dict={<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: 1.0}, options=None, run_metadata=None)\n    872         compat.as_bytes(options.SerializeToString())) if options else None\n    873     run_metadata_ptr = tf_session.TF_NewBuffer() if run_metadata else None\n    874 \n    875     try:\n    876       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 877                          run_metadata_ptr)\n        run_metadata_ptr = None\n    878       if run_metadata:\n    879         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n    880         run_metadata.ParseFromString(compat.as_bytes(proto_data))\n    881     finally:\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self=<tensorflow.python.client.session.Session object>, handle=None, fetches=[<tf.Tensor 'loss/mul:0' shape=() dtype=float32>, <tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>, <tf.Operation 'training/group_deps' type=NoOp>], feed_dict={<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1, 0],\n       [0, 1],\n       [1, 0],\n   ...1],\n       [1, 0],\n       [0, 1],\n       [1, 0]]), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: 1.0}, options=None, run_metadata=None)\n   1095     final_targets = fetch_handler.targets()\n   1096     # We only want to really perform the run if fetches or targets are provided,\n   1097     # or if the call is a partial run that specifies feeds.\n   1098     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1099       results = self._do_run(handle, final_targets, final_fetches,\n-> 1100                              feed_dict_tensor, options, run_metadata)\n        feed_dict_tensor = {<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...  [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1., 0.],\n       [0., 1.],\n       [1., 0....       [0., 1.],\n       [1., 0.]], dtype=float32), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: array(True)}\n        options = None\n        run_metadata = None\n   1101     else:\n   1102       results = []\n   1103     return fetch_handler.build_results(self, results)\n   1104 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self=<tensorflow.python.client.session.Session object>, handle=None, target_list=[<tf.Operation 'training/group_deps' type=NoOp>], fetch_list=[<tf.Tensor 'loss/mul:0' shape=() dtype=float32>, <tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>], feed_dict={<tf.Tensor 'lstm_1_input:0' shape=(?, 10, 28) dtype=float32>: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...  [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), <tf.Tensor 'activation_1_target:0' shape=(?, ?) dtype=float32>: array([[1., 0.],\n       [0., 1.],\n       [1., 0....       [0., 1.],\n       [1., 0.]], dtype=float32), <tf.Tensor 'activation_1_sample_weights:0' shape=(?,) dtype=float32>: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tf.Tensor 'dropout_1/keras_learning_phase:0' shape=() dtype=bool>: array(True)}, options=None, run_metadata=None)\n   1267         raise RuntimeError('partial_run() requires empty target_list.')\n   1268       return self._call_tf_sessionprun(handle, feed_dict, fetch_list)\n   1269 \n   1270     if handle is None:\n   1271       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-> 1272                            run_metadata)\n        run_metadata = None\n   1273     else:\n   1274       return self._do_call(_prun_fn, handle, feeds, fetches)\n   1275 \n   1276   def _do_call(self, fn, *args):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self=<tensorflow.python.client.session.Session object>, fn=<function BaseSession._do_run.<locals>._run_fn>, *args=({<tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28a50> >: array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...  [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28ba0> >: array([[1., 0.],\n       [0., 1.],\n       [1., 0....       [0., 1.],\n       [1., 0.]], dtype=float32), <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28b10> >: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28b40> >: array(True)}, [<tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28bd0> >, <tensorflow.python.pywrap_tensorflow_internal.TF...Object of type 'TF_Output *' at 0x7f4230a28c00> >], [<Swig Object of type 'TF_Operation *'>], None, None))\n   1286         try:\n   1287           op = self._graph.get_operation_by_name(node_name)\n   1288           node_def = op.node_def\n   1289         except KeyError:\n   1290           pass\n-> 1291       raise type(e)(node_def, op, message)\n        e = undefined\n        node_def = name: \"lstm_1/while/MatMul_7\"\nop: \"MatMul\"\ninput... key: \"transpose_b\"\n  value {\n    b: false\n  }\n}\n\n        op = <tf.Operation 'lstm_1/while/MatMul_7' type=MatMul>\n        message = 'Blas GEMM launch failed : a.shape=(10, 512), b.s...job:localhost/replica:0/task:0/device:CPU:0\"]()]]'\n   1292 \n   1293   def _extend_graph(self):\n   1294     with self._graph._session_run_lock():  # pylint: disable=protected-access\n   1295       tf_session.ExtendSession(self._session)\n\nInternalError: Blas GEMM launch failed : a.shape=(10, 512), b.shape=(512, 512), m=10, n=512, k=512\n\t [[Node: lstm_1/while/MatMul_7 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/AddN_13\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/while/Switch_2:1, lstm_1/while/MatMul_7/Enter)]]\n\t [[Node: metrics/acc/Mean/_107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3328_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'lstm_1/while/MatMul_7', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-f7262d93c938>\", line 6, in <module>\n    accuracies = cross_val_score(estimator = classifier, X = train_X, y = train_Y, cv = 2, n_jobs = -1)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 342, in cross_val_score\n    pre_dispatch=pre_dispatch)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 206, in cross_validate\n    for train, test in cv.split(X, y, groups))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 749, in __call__\n    n_jobs = self._initialize_backend()\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 547, in _initialize_backend\n    **self._backend_args)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 317, in configure\n    self._pool = MemmapingPool(n_jobs, **backend_args)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\", line 600, in __init__\n    super(MemmapingPool, self).__init__(**poolargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/pool.py\", line 420, in __init__\n    super(PicklingPool, self).__init__(**poolargs)\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n    self._repopulate_pool()\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n    w.start()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\n    self._popen = self._Popen(self)\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n    return Popen(process_obj)\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 20, in __init__\n    self._launch(process_obj)\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 74, in _launch\n    code = process_obj._bootstrap()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 209, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\", line 140, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n  File \"<ipython-input-7-55700185ea87>\", line 4, in build_classifier\n    model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 497, in add\n    layer(x)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 500, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 2112, in call\n    initial_state=initial_state)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 609, in call\n    input_length=timesteps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2771, in rnn\n    swap_memory=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2757, in _step\n    tuple(constants))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 600, in step\n    return self.cell.call(inputs, states, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 1908, in call\n    self.recurrent_kernel_o))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 1076, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 2018, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4456, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(10, 512), b.shape=(512, 512), m=10, n=512, k=512\n\t [[Node: lstm_1/while/MatMul_7 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/AddN_13\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/while/Switch_2:1, lstm_1/while/MatMul_7/Enter)]]\n\t [[Node: metrics/acc/Mean/_107 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3328_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\n___________________________________________________________________________"
          ]
        }
      ]
    }
  ]
}